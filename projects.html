
<!DOCTYPE html>
<html lang="zxx">

<head>
    <title>projects</title>
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta charset="utf-8" />
    <meta name="keywords" content="Interface Responsive web template, Bootstrap Web Templates, Flat Web Templates, Android Compatible web template, 
	SmartPhone Compatible web template, free WebDesigns for Nokia, Samsung, LG, Sony Ericsson, Motorola web design" />
    <script>
        addEventListener("load", function () {
            setTimeout(hideURLbar, 0);
        }, false);

        function hideURLbar() {
            window.scrollTo(0, 1);
        }
    </script>
    <!-- Custom Theme files -->
    <link href="css/projects/bootstrap.css" type="text/css" rel="stylesheet" media="all">
    <link href="css/projects/gridview.css" rel="stylesheet" type="text/css">
    <!-- font-awesome icons -->
    <link href="css/font-awesome.min.css" rel="stylesheet">
    <!-- //Custom Theme files -->
    <!-- online-fonts -->
    <link href="https://fonts.googleapis.com/css?family=Montserrat:100,100i,200,200i,300,300i,400,400i,500,500i,600,600i,700,700i,800,800i,900,900i"
        rel="stylesheet">
        <style>
            a{
                color: white;
            }
        </style>
</head>

<body id="page-top" data-spy="scroll" data-target=".navbar-fixed-top">
    <!-- grid view -->
    <nav class="shift">
        <div class="branding">
            <figure>
                <img class="logo" src="img/robosoc.png">
            </figure>
            <div class="brand">   
            <h3><span>ROBOTICS SOCIETY</span><br/>NIT-Hamirpur</h3>
            </div>
        </div>
        <div class="nav-links">
            <a href="index.html">Home</a>
            <a href="activities.html">Activities</a>
            <a href="projects.html">Projects</a>
            <a href="Blog.html">Blog</a>
            <a href="members.html">Members</a>
        </div>
        <img class="ham-burg" src="img/hamburger-icon-white.png" width=60px>
    </nav>
    <section class="banner">
        <div class="banner-box">
            <h1>Projects</h1>
            <h3>Robotics Society NITH</h3>
        </div>
    </section>
        <div class="container">
            <div class="title-sec-agile text-center">
               
                <h1 class="agile-head">PROJECTS</h1>
            </div>
            <div class="row py-3">
                <div class="col-lg-12 my-3">
                    <div class="pull-right">
                        <div class="btn-group">
                            <button class="btn btn-info" id="list">
                                <i class="fa fa-list-ul"></i>
                            </button>
                            <button class="btn btn-danger" id="grid">
                                <i class="fa fa-th"></i>
                            </button>
                        </div>
                    </div>
                </div>
            </div>
            <div id="products" class="row view-group">
                <div class="item col-lg-4">
                    <div class="thumbnail card">
                        <div class="img-event">
                            <img class="group list-group-image img-fluid" src="img/projects/a1.jpg" alt="" />
                        </div>
                        <div class="caption card-body">
                            <h4 class="group card-title inner list-group-item-heading">
                                SLAM</h4>
                            <p class="group inner list-group-item-text">
                                <b>Our objective is to develop a mobile robot which can perform S.L.A.M in an unknown environment to produce map of the particular environment and use path planning algorithms to perform autonomous navigation.</b></p><span id="dots1"></span><div class="btn-container">
<button onclick="myFunction1()" id="myBtn1" class="button1">Read more</button>
</div><span id="text1">
                                <p> Robots need a sense of its location in an environment to navigate autonomously. Let's take an example of robot serving as a waiter in an Hotel. This robot will need the map of the hotel to determine its path and need  to know the position of the robot in the map. And if robots are deployed in an unknown environment, it needs to construct its' map and localize itself simultaneously while navigating as human beings do. In this project, we will be using the Kinect as a depth sensor and wheel odometry from iroomba will be used. The subscribing and publishing of these data will be done using R.O.S (Robot Operating System)</span> </p>
                        </div>
                    </div>
                </div>
                <div class="item col-lg-4">
                    <div class="thumbnail card">
                        <div class="img-event">
                            <img class="group list-group-image img-fluid" src="img/projects/a2.jpg" alt="" />
                        </div>
                        <div class="caption card-body">
                            <h4 class="group card-title inner list-group-item-heading">
                                HUMANOID</h4>
                            <p class="group inner list-group-item-text">
                               <b>The main aim of this project is to study the dynamics and kinematics of biped humanoid in different postures and  balancing during walking and running</b></p><span id="dots2"></span><div class="btn-container">
<button onclick="myFunction2()" id="myBtn2" class="button1">Read more</button>
</div><span id="text2">
                               <p>Humanoid robotics is an emerging and challenging research field, which has received significant attention during the past years and will continue to play a central role in robotics research and in many applications of the 21st century.              
<br>
      We are also working on the development of human shaped bots so as to study its dynamics and movements. For this we firstly made a Human shaped bot using the SERVO motors, Wood and thin metal sheets were used to make the structure steady and rigid . 17 DOF (Degree Of  Freedom) were allowed to this bot.

      At the starting we are working on its Biped movements to check its proper balancing by itself. MatLab model of the Humanoid was designed to facilitate easy simulation and calculations. It was controlled using Arduino Mega, A special circuitry was designed  for proper regulation of voltage and cooling unit was also attached to cool the processors and regulators. </span></p>
      
                        </div>
                    </div>
                </div>
                <div class="item col-lg-4">
                    <div class="thumbnail card">
                        <div class="img-event">
                            <img class="group list-group-image img-fluid" src="img/projects/a3.jpg" alt="" />
                        </div>
                        <div class="caption card-body">
                            <h4 class="group card-title inner list-group-item-heading">
                               3D SCANNER</h4>
                            <p class="group inner list-group-item-text">
                                <b>Our objective is to develop an affordable 3D scanner with higher resolution for personal use.</b></p>
                                <span id="dots3"></span><div class="btn-container">
<button onclick="myFunction3()" id="myBtn3" class="button1">Read more</button>
</div><span id="text3">
                                <p>3D scanner is a device that analyses a real-world object or environment to collect data on its shape and possibly its appearance. The collected data can then be used to construct digital three-dimensional image. Our 3D scanner works by illuminating an object with line laser and then using 3D triangulation to generate a point cloud for each location where the laser hits the model. It is also having a turntable over which the object to be scanned is placed.  Neighbouring points are then connected as triangles to form a 3D model. Our scanner uses the freelss software to collect the data and construct the 3D model.

​<br>

​      All of the software runs on board the Raspberry Pi, so there is no requirement of drivers or software packages to install. A web browser is used to communicate with the scanner on your home network.  Once a scan is performed, the web browser is used to download the resulting models.​

​<br>

      Our 3D scanner consists of a rotating table using stepper motor, 1 camera module, 2 laser modules and a processing software  freelss on Raspberry Pi.</span></p>
                        </div>
                    </div>
                </div>
                <div class="item col-lg-4">
                    <div class="thumbnail card">
                        <div class="img-event">
                            <img class="group list-group-image img-fluid" src="img/projects/a4.jpg" alt="" />
                        </div>
                        <div class="caption card-body">
                            <h4 class="group card-title inner list-group-item-heading">
                                DRIVERLESS CAR</h4>
                            <p class="group inner list-group-item-text">
                               <b>Our objective is to develop a prototype of driver-less car with scale-down size which can detect the road and follow the path and also recognizes the traffic signal.</b></p>
                               <span id="dots4"></span><div class="btn-container">
<button onclick="myFunction4()" id="myBtn4" class="button1">Read more</button>
</div><span id="text4">
                               <p>The car consists of a Raspberry Pi with a camera and an ultrasonic sensor as inputs. The neural network is trained in OpenCV using back propagation method. Once training is done, weights are saved. To generate predictions, the same neural network is constructed and loaded with the trained xml file. This project adapted the shape-based approach and used Haar feature-based cascade classifiers for object detection. Since each object requires its own classifier and follows the same process in training and detection, this project only focused on stop sign and traffic light detection.
<br>
      OpenCV provides a trainer as well as detector. <br>

      For distance measurement aspect, the ultrasonic sensor is only used to determine the distance to an obstacle in front of the RC car and provides accurate results. On the other hand, Pi camera provides “good enough” measurement results. In fact, as long as we know the corresponding number to the actual distance, we know when to stop the RC car.</span></p>
                        </div>
                    </div>
                </div>
                <div class="item col-lg-4">
                    <div class="thumbnail card">
                        <div class="img-event">
                            <img class="group list-group-image img-fluid" src="img/projects/a5.jpg" alt="" />
                        </div>
                        <div class="caption card-body">
                            <h4 class="group card-title inner list-group-item-heading">
                                Teleoperation using leap motion</h4>
                            <p class="group inner list-group-item-text"><b>
                            Our objective is to develop a system which can reproduce the gesture of our hand for teleoperation using leap motion.</b></p>
                            <span id="dots5"></span><div class="btn-container">
<button onclick="myFunction5()" id="myBtn5" class="button1">Read more</button>
</div><span id="text5">
                            <p>Teleoperation indicates operation of a machine at a distance. It is similar in meaning to the phrase "remote control" but is usually encountered in research, academic and technical environments. It is most commonly associated with robotics and mobile robots but can be applied to a whole range of circumstances in which a device or machine is operated by a person from a distance.We used leap motion as a interface device. Leap motion is a device which captures hand and finger motions accurately up to a great extent and requires no contact with the device. It captures hand movements in virtual reality which can easily be developed using common programming languages to read different values and send these values to a web socket and interface it with a microcontroller.​<br>

      A robotic hand was made using servo motors so as to get precise finger movements of robotic hand.<br>

      Leap motion data is sent to a web socket which is interfaced with a microcontroller and the microcontroller give the commands to each servo motor of robotic hand so as to get human hand like movements.</span></p>
                        </div>
                    </div>
                </div>
                <div class="item col-lg-4 thumb-last">
                    <div class="thumbnail card">
                        <div class="img-event">
                            <img class="group list-group-image img-fluid" src="img/projects/a6.jpg" alt="" />
                        </div>
                        <div class="caption card-body">
                            <h4 class="group card-title inner list-group-item-heading">
                                Vision based PnP robotic arm</h4>
                            <p class="group inner list-group-item-text">
                                 <b>Our objective is to develop a robotic arm for pick and place operation using opencv and robotic arm.</b></p>
                                 <span id="dots6"></span><div class="btn-container">
<button onclick="myFunction6()" id="myBtn6" class="button1">Read more</button>
</div><span id="text6">
                                 <p>Most of the industrial robots need to recognise the objects and determine the co-ordinate of the object for pick and place operation. In this project, we are implementing a vision system on the robotic arm to recognise objects and their coordinates using openCV. The position of the object is serial communicated to the servos of the robotic arm and the particular pick & place operation is performed.</p></span>
                        </div>
                    </div>
                </div>
            </div>
        </div>
    </section>
    <!-- //grid view -->
<script>
function myFunction1() {
	var dots1 = document.getElementById("dots1");
  var moreText = document.getElementById("text1");
  var btnText = document.getElementById("myBtn1");

  if (dots1.style.display === "none") {
    dots1.style.display = "inline";
    btnText.innerHTML = "Read more"; 
    moreText.style.display = "none";
  } else {
    dots1.style.display = "none";
    btnText.innerHTML = "Read less"; 
    moreText.style.display = "inline";
  }
}
</script>
<script>
function myFunction2() {
	var dots2 = document.getElementById("dots2");
  var moreText = document.getElementById("text2");
  var btnText = document.getElementById("myBtn2");

  if (dots2.style.display === "none") {
    dots2.style.display = "inline";
    btnText.innerHTML = "Read more"; 
    moreText.style.display = "none";
  } else {
    dots2.style.display = "none";
    btnText.innerHTML = "Read less"; 
    moreText.style.display = "inline";
  }
}
</script>
<script>
function myFunction3() {
	var dots3 = document.getElementById("dots3");
  var moreText = document.getElementById("text3");
  var btnText = document.getElementById("myBtn3");

  if (dots3.style.display === "none") {
    dots3.style.display = "inline";
    btnText.innerHTML = "Read more"; 
    moreText.style.display = "none";
  } else {
    dots3.style.display = "none";
    btnText.innerHTML = "Read less"; 
    moreText.style.display = "inline";
  }
}
</script>
<script>
function myFunction4() {
	var dots4 = document.getElementById("dots4");
  var moreText = document.getElementById("text4");
  var btnText = document.getElementById("myBtn4");

  if (dots4.style.display === "none") {
    dots4.style.display = "inline";
    btnText.innerHTML = "Read more"; 
    moreText.style.display = "none";
  } else {
    dots4.style.display = "none";
    btnText.innerHTML = "Read less"; 
    moreText.style.display = "inline";
  }
}
</script>
<script>
function myFunction5() {
	var dots5 = document.getElementById("dots5");
  var moreText = document.getElementById("text5");
  var btnText = document.getElementById("myBtn5");

  if (dots5.style.display === "none") {
    dots5.style.display = "inline";
    btnText.innerHTML = "Read more"; 
    moreText.style.display = "none";
  } else {
    dots5.style.display = "none";
    btnText.innerHTML = "Read less"; 
    moreText.style.display = "inline";
  }
}
</script>
<script>
function myFunction6() {
	var dots6 = document.getElementById("dots6");
  var moreText = document.getElementById("text6");
  var btnText = document.getElementById("myBtn6");

  if (dots6.style.display === "none") {
    dots6.style.display = "inline";
    btnText.innerHTML = "Read more"; 
    moreText.style.display = "none";
  } else {
    dots6.style.display = "none";
    btnText.innerHTML = "Read less"; 
    moreText.style.display = "inline";
  }
}
</script>


    <!-- js -->
    <script src="js/projects/jquery-2.2.3.min.js"></script>
    <!-- //js -->
    <script src="js/projects/gridview.js"></script>
    <!-- //grid view -->
    <!--  menu toggle -->
    <script src="js/projects/menu.js"></script>
    <!-- Scrolling Nav JavaScript -->
    <script src="js/projects/scrolling-nav.js"></script>
    <!-- start-smooth-scrolling -->
    <script src="js/projects/move-top.js"></script>
    <script src="js/projects/easing.js"></script>
    <script>
        jQuery(document).ready(function ($) {
            $(".scroll").click(function (event) {
                event.preventDefault();

                $('html,body').animate({
                    scrollTop: $(this.hash).offset().top
                }, 1000);
            });
        });
    </script>
    <!-- //end-smooth-scrolling -->
    <!-- smooth-scrolling-of-move-up -->
    <script>
        $(document).ready(function () {
            /*
            var defaults = {
                containerID: 'toTop', // fading element id
                containerHoverID: 'toTopHover', // fading element hover id
                scrollSpeed: 1200,
                easingType: 'linear' 
            };
            */

            $().UItoTop({
                easingType: 'easeOutQuart'
            });

        });
    </script>
    <script src="js/projects/SmoothScroll.min.js"></script>
    <!-- //smooth-scrolling-of-move-up -->
    <!-- Bootstrap core JavaScript
================================================== -->
    <!-- Placed at the end of the document so the pages load faster -->
    <script src="js/projects/bootstrap.js"></script>
</body>

</html>
